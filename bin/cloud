#!/bin/sh

# SETTINGS

context=${CLOUD:-local}
hosts_path=/etc/hosts
bin_path=/usr/local/bin
nfsd_path=/sbin/nfsd
tcc_path=/Library/Application\ Support/com.apple.TCC/TCC.db
rails_pod=rails

agent_name=com.cloud
agent_filename=$agent_name.plist

tmp_path=/tmp/chi-cloud
tmp_repo_path=$tmp_path/repo
tmp_base_path=$tmp_path/base
tmp_cloud_path=$tmp_base_path/cloud
tmp_conf_path=$tmp_path/conf

exports_path=/etc/exports
exports_home_path=/System/Volumes/Data$HOME

s3_url=https://chi-rb.s3.amazonaws.com
s3_initrd_url=$s3_url/initrd
s3_vmlinuz_url=$s3_url/vmlinuz
s3_disk_url=$s3_url/disk.img.xz

repo_path=/usr/local/cloud
repo_app_path=$repo_path/app
repo_base_path=$repo_app_path/base
repo_vm_path=$repo_path/vm
repo_initrd_path=$repo_vm_path/initrd
repo_vmlinuz_path=$repo_vm_path/vmlinuz
repo_disk_path=$repo_vm_path/disk.img.xz
repo_bin_path=$repo_path/bin
repo_xhyve_path=$repo_bin_path/xhyve
repo_ruby_path=$repo_bin_path/ruby

user_cloud_path=$HOME/.cloud
user_conf_path=$user_cloud_path/conf
user_disk_path=$user_cloud_path/disk.img
user_agent_path=$HOME/Library/LaunchAgents/$agent_filename

vm_user=hacker
vm_name=cloud
vm_mem=4G
vm_cpus=4

k3s_latest_url=https://github.com/rancher/k3s/releases/latest
k3s_path=/usr/local/bin/k3s

net_setting_names=(
	mac_ip
	vm_ip
)
user_setting_names=(
	vm_mem
	vm_cpus
)
user_setting_descs=(
	'Virtual machine memory'
	'Virtual machine cpus'
)

# UTILS

read_json() {
	cat - |
	grep -oE "$1\": \"[^\"]+" |
	head -n1 |
	awk '{ print $2 }' |
	tr -d '"'
}

wait_for() {
	while [ "$($1)" != $2 ]; do
		echo .
		sleep 30
	done
}

ok() {
	if [ "$beginned" = true ]; then
		echo Ok
	fi
}

complete() {
	ok
	if [ "$beginned" = true ]; then
		echo
	fi
	echo Complete
}

authorize() {
	echo "Enter username: \c"
	read user
	echo "Enter password: \c"
	read -s pass
}

error() {
	echo $@ >&2
	exit 1
}

begin() {
	ok
	if [ "$beginned" = true ]; then
		echo
	fi
	echo "~> $@"
	beginned=true
}

correct() {
	echo "Correct (Y/n)? \c"
	read yn
	if [ "$yn" = n ]; then
		return 1
	fi
}

unknown() {
	if [ ! -z $1 ]; then
		echo "Unknown command \`$1\` \n"
	fi
}

gen_id() {
	echo $(uuidgen | tr '[:upper:]' '[:lower:]')
}

edit() {
	if [ -z $EDITOR ]; then
		echo Edit $1 to setup environment
	else
		$EDITOR $1
	fi
}

add_conf() {
	if [ $2 = - ]; then
		conf=$(cat -)
	else
		if [ -z $3 ]; then
			conf="$2=${!2}"
		else
			conf="$2=$3"
		fi
	fi
	echo "$conf" >> $1
}

del_conf() {
	sed -i '' "/$2/d" $1 
}

bin_authorized() {
	sudo sqlite3 "$tcc_path" "select 1 from access where service=\"kTCCServiceSystemPolicyAllFiles\" and client=\"$1\""
}

show_file() {
	osascript -e 'tell application "Finder"' -e activate -e "reveal POSIX file \"$1\"" -e end tell
}

open_privacy() {
	open "x-apple.systempreferences:com.apple.preference.security?Privacy_AllFiles" 
}

authorize_bin() {
	while [ -z $(bin_authorized $1) ]; do
		open_privacy
		echo Please drag the binary into the full disk access tab
		show_file $1
		echo Press enter once done
		read
	done
}

host_exists() {
	sudo grep $vm_name $hosts_path >/dev/null 2>&1
}

export_exists() {
	test -f $exports_path && sudo grep $exports_home_path $exports_path >/dev/null 2>&1
}

# COMPILE

compile_tpl() {
	output=$(cat "$1")
	subs=$(grep -o '{{ [a-z_. ]* }}' "$1" | uniq)
	while read sub; do
		sub_args=( $(echo $sub | sed 's/{{ //' | sed 's/ }}//') )
		case $sub in
		{{\ render\ *)
			render_path=${sub_args[1]}
			vars=("${sub_args[@]:2}")
			for var in $vars; do
				declare $var
			done
			snippet_path=$cloud_snippets_path/$render_path.yml
			sub_value=$(compile_tpl "$snippet_path" $2 $3 | sed 's/\//\\\//g' | tr '\n' '\r')
			output=$(echo "$output" | sed "s/$sub/$sub_value/g" | tr '\r' '\n' | sed '/^$/d')
		;;
		*)
			sub_name=${sub_args[0]}
			cloud_sub_name=cloud_${sub_name}
			pod_sub_name=${2}_${sub_name}
			if [ ! -z "${!pod_sub_name}" ]; then
				target_sub_name=$pod_sub_name
			elif [ ! -z "${!cloud_sub_name}" ]; then
				target_sub_name=$cloud_sub_name
			elif [ ! -z "${!sub_name}" ]; then
				target_sub_name=$sub_name
			else
				error $sub undefined, compiling $1 in $cloud_env
			fi
			sub_value=$(echo ${!target_sub_name} | sed 's/\//\\\//g')
			output=$(echo "$output" | sed "s/$sub/$sub_value/g")
		;;
		esac
	done <<-EOF
		$(echo "$subs")
	EOF
	echo "$output"
}

compile_tpls() {
	paths=()
	names=()
	pod_names=()
	while read path; do
		paths+=("$path")
	done <<< "$(find "$cloud_compile_path" -type f -name '*.yml')"
	for i in ${!paths[@]}; do
		path=${paths[$i]}
		name=$(basename "$path" | sed 's/\.yml$//' | tr - _)
		names+=($name)
		pod_name=$(echo $name | tr _ -)
		pod_names+=($pod_name)
		declare "${name}_host=$pod_name"
		declare "${name}_name=$pod_name"
	done
	for i in ${!paths[@]}; do
		path=${paths[$i]}
		name=${names[$i]}
		pod_name=${pod_names[$i]}
		apply_path=$cloud_apply_path/${path#$cloud_compile_path/}
		mkdir -p "$(dirname "$apply_path")"
		echo "$(compile_tpl "$path" $name $pod_name)" >> "$apply_path"
	done
}

compile_statics() {
	if [ $context = remote ]; then
		case $cloud_provider in
		aws)
			cat <<-YML > "$cloud_docker_path"
				apiVersion: v1
				kind: ConfigMap
				metadata:
				  name: docker
				data:
				  config.json: |
				    { "credsStore": "ecr-login" }
			YML
			case $cloud_provider in
			aws)
				credentials=$(vm_ssh cat /home/hacker/.aws/credentials | base64)
				cat <<-YML > "$cloud_aws_path"
					apiVersion: v1
					kind: Secret
					type: Opaque
					metadata:
					  name: aws
					data:
					  credentials: $credentials
				YML
			;;
			esac
		;;
		esac
	fi
	cat <<-YML > "$cloud_namespace_path"
		apiVersion: v1
		kind: Namespace
		metadata:
		  name: $cloud_id
		  labels:
		    name: $cloud_id
	YML
	escaped_cloud_apply_path=$(echo "$cloud_apply_path/" | sed 's/\//\\\//g')
	resources=$(find "$cloud_apply_path" -name '*.yml' | sed "s/$escaped_cloud_apply_path//g" | sed 's/^/  - /g')
	cat <<-YML > "$cloud_kustomization_path"
		namespace: $cloud_id
		resources:
		$resources
	YML
}

compile() {
	begin Compiling YAMLs
	find "$cloud_tmp_path" ! -name 'images' -maxdepth 1 -mindepth 1 -exec rm -rf {} +
	mkdir -p "$cloud_compile_path"
	case $1 in
	build)
		while read dir_path; do
			name=$(basename "$dir_path")
			target_path="$cloud_compile_path/$name.yml"
			mkdir -p "$cloud_images_path"
			case $context in
			local)
				cat <<-YML > "$target_path"
					apiVersion: v1
					kind: Pod
					metadata:
					  name: {{ name }}-build
					  labels:
					    name: {{ name }}-build
					spec:
					  restartPolicy: Never
					  containers:
					  - image: gcr.io/kaniko-project/executor:latest
					    name: kaniko
					    args:
					    - --no-push
					    - --tarPath=/rails/tmp/cloud/images/{{ name }}.tar
					    - --destination=image
					    - --context=/rails/cloud/build/rails
					    - --dockerfile=/Dockerfile
					    - --build-arg=RAILS_ENV={{ cloud_env }}
					    volumeMounts:
					    - name: rails
					      mountPath: /rails
					  volumes:
					  - name: rails
					    hostPath:
					      path: {{ app_path }}
				YML
			;;
			remote)
				case $cloud_provider in
				aws)
					cat <<-YML > "$target_path"
						apiVersion: v1
						kind: Pod
						metadata:
						  name: {{ name }}-build
						  labels:
						    name: {{ name }}-build
						spec:
						  restartPolicy: Never
						  containers:
						  - image: gcr.io/kaniko-project/executor:latest
						    name: kaniko
						    args:
						    - --destination={{ repo }}
						    - --context=/rails/cloud/build/{{ name }}
						    - --dockerfile=/Dockerfile
						    - --build-arg=RAILS_ENV={{ cloud_env }}
						    volumeMounts:
						    - name: rails
						      mountPath: /rails
						    - name: docker
						      mountPath: /kaniko/.docker/
						    - name: aws
						      mountPath: /root/.aws/
						  volumes:
						  - name: rails
						    hostPath:
						      path: {{ app_path }}
						  - name: docker
						    configMap:
						      name: docker
						  - name: aws
						    secret:
						      secretName: aws
					YML
				;;
				esac
			;;
			esac
		done <<< "$(find "$cloud_build_path" -type d -maxdepth 1 -mindepth 1)"
	;;
	deploy)
		while read yml_path; do
			name=$(basename "$yml_path")
			target_path="$cloud_compile_path/$name"
			cp "$yml_path" "$target_path"
		done <<< "$(find "$cloud_deploy_path/base" "$cloud_deploy_path/$cloud_env" -name \*.yml)"
	;;
	esac
	compile_tpls
	compile_statics
}

# CLOUD 

cloud_kubectl() {
	cmd=$@
	if [ ! -z $cloud_id ]; then
		cmd="--namespace $cloud_id $cmd"
	fi
	vm_kubectl $cmd
}

cloud_find_pod() {
	name=${1:-$rails_pod}
	echo $(cloud_kubectl get pod -l "name=$name" -o jsonpath='{.items[0].metadata.name}')
}

cloud_pod_exec() {
	name=$1
	shift
	cloud_kubectl exec -it $name -- $@
}

cloud_dir_exists() {
	test -d "$cloud_path"
}

cloud_load() {
	cloud_set_paths
	cloud_env=${RAILS_ENV:-development}
	if [ $context = remote ]; then
		. "$cloud_remote_path"
	else
		. "$cloud_local_path"
	fi
	cloud_ensure_env $cloud_env
	. "$cloud_base_path"
	. "$cloud_env_path"
	cloud_id=$cloud_name-$cloud_env
}

cloud_ensure_dir() {
	if ! cloud_dir_exists; then
		error No cloud directory found
	fi
}

cloud_env_exists() {
	if [ ! -z $1 ]; then
		cloud_env_path=$cloud_envs_path/$1
		if [ ! -f "$cloud_env_path" ]; then
			return 1
		fi
	else
		error No environment specified
	fi
}

cloud_ensure_env() {
	cloud_ensure_dir
	if ! cloud_env_exists $1; then
		error Environment $1 not exists
	fi
}

cloud_choose_name() {
	if [ -z $cloud_name ]; then
		echo "Enter name: \c"
		read	cloud_name
		add_conf $cloud_base_path cloud_name
	fi
}

cloud_choose_port() {
	if [ -z $rails_cluster_port ]; then
		echo "Enter port: \c"
		read	rails_cluster_port
		add_conf $cloud_dev_path rails_cluster_port
	fi
}

cloud_choose_provider() {
	if [ -z $cloud_provider ]; then
		echo 'Choose provider: Amazon (A)?'
		read cloud_provider
		case $cloud_provider in
		A|a|'')
			cloud_provider=aws
		;;
		esac
		add_conf $cloud_base_path cloud_provider
	fi
}

cloud_set_remote() {
	case $cloud_provider in
	aws)
		aws_create_cloud
	;;
	esac
}

cloud_choose_settings() {
	begin Choosing Settings
	if [ -z $cloud_name ] || [ -z $rails_cluster_port ] || [ -z $cloud_provider ]; then
		cloud_choose_name
		cloud_choose_port
		cloud_choose_provider
	else
		echo Already setted
	fi
}

cloud_set_paths() {
	if [ ! -z "$1" ]; then
		if [ ${1:0:1} = / ]; then
			app_path=$1
		else
			app_path=$PWD/$1
		fi
	else
		app_path=$PWD
	fi
	cloud_path=$app_path/cloud
	cloud_tmp_path=$app_path/tmp/cloud
	cloud_images_path=$cloud_tmp_path/images
	cloud_compile_path=$cloud_tmp_path/compile
	cloud_apply_path=$cloud_tmp_path/apply
	cloud_docker_path=$cloud_apply_path/docker.yml
	cloud_aws_path=$cloud_apply_path/aws.yml
	cloud_namespace_path=$cloud_apply_path/namespace.yml
	cloud_kustomization_path=$cloud_apply_path/kustomization.yml
	cloud_contexts_path=$cloud_path/contexts
	cloud_local_path=$cloud_contexts_path/local
	cloud_remote_path=$cloud_contexts_path/remote
	cloud_envs_path=$cloud_path/envs
	cloud_base_path=$cloud_envs_path/base
	cloud_dev_path=$cloud_envs_path/development
	cloud_prod_path=$cloud_envs_path/production
	cloud_build_path=$cloud_path/build
	cloud_deploy_path=$cloud_path/deploy
	cloud_snippets_path=$cloud_deploy_path/snippets
	cloud_samples_path=$cloud_tmp_path/samples
	cloud_sample_paths=(
		config/puma.rb
		config/database.yml
		config/cable.yml
		test/test_helper.rb
		test/application_system_test_case.rb
	)
}

cloud_clone() {
	begin Cloning Repository
	if [ ! -d $repo_path ]; then
		mkdir -p $tmp_path
		git clone git@github.com:chi-rb/chi-cloud.git $tmp_repo_path
		sudo mv $tmp_repo_path $repo_path
	else
		echo Already cloned
	fi
}

cloud_authorize_nfsd() {
	begin Authorizing NFSD
	if ! bin_authorized $nfsd_path; then
		authorize_bin $nfsd_path
		sudo nfsd restart
	else
		echo Already authorized
	fi
}

cloud_authorize_xhyve() {
	begin Authorizing XHYVE
	if ! bin_authorized $repo_xhyve_path; then
		authorize_bin $repo_xhyve_path
	else
		echo Already authorized
	fi
}

cloud_update_rc() {
	begin Prepending PATH
	ruby=$(which ruby)
	if [ $ruby != $ruby_path ]; then
		cat <<-DOC
			Add this into your shell rc file:
			PATH=/usr/local/cloud/bin:$PATH

			And then:
			. /shell-rc-path
		DOC
	else
		echo Already updated	
	fi
}

cloud_install() {
	cloud_clone
	cloud_authorized_nfsd
	cloud_authorized_xhyve
	vm_install nested
	cloud_update_rc
	complete
}

cloud_delete_settings() {
	begin Deleting Settings
	if [ -d $user_cloud_path ]; then
		rm -rf $user_cloud_path
	else
		echo Not found
	fi
}

cloud_delete_repo() {
	begin Deleting Cloud
	if [ -d $repo_path ]; then
		sudo rm -rf $repo_path
	else
		echo Not found
	fi
}

cloud_uninstall() {
	vm_uninstall nested
	cloud_delete_settings
	cloud_delete_repo
	complete
}

cloud_update() {
	begin Updating Repository
	current_path=$PWD
	cd $repo_path
	git pull
	current_branch=$(git branch | cut -d ' ' -f2)
	new_branch=${2:-master}
	if [ $current_branch != $new_branch ]; then
		git checkout $new_branch
	fi
	cd "$current_path"
	complete
}

cloud_resolve_db() {
	cloud_db=postgres
	while getopts 'd:' o; do
		case "$o" in
		d)
			if [ $OPTARG != postgres ] && [ $OPTARG != mysql ]; then
				error Unknown database $OPTARG
			else
				cloud_db=$OPTARG
			fi
		;;
		esac
	done
	add_conf "$cloud_base_path" cloud_db
}

cloud_generate_tmp() {
	mkdir -p $tmp_path
	rm -rf $tmp_base_path
	cp -r $repo_base_path $tmp_base_path
	patch_name=$cloud_db.patch
	patch_path=$tmp_path/$patch_name
	cp $repo_app_path/$patch_name $tmp_path
	patch -s -p0 -d $tmp_path < $patch_path
	rm $patch_path
}

cloud_generate_app() {
	mkdir -p "$(dirname "$app_path")"
	mv $tmp_base_path "$app_path"
	git init "$app_path"
}

cloud_generate_dir() {
	mv $tmp_cloud_path "$cloud_path"
	mkdir -p "$cloud_samples_path"
	for sample_path in "${cloud_sample_paths[@]}"; do
		destination_path=$cloud_samples_path/$sample_path
		mkdir -p "$(dirname "$destination_path")"
		cp $tmp_base_path/$sample_path "$destination_path"
	done
	rm -rf $tmp_base_path
	echo You might need to tweak a few files, try using tmp/cloud/samples as a guideline
}

cloud_generate() {
	begin Generating Directory
	if ! cloud_dir_exists; then
		cloud_resolve_db
		shift $((OPTIND-1))
		cloud_set_paths "$@"
		cloud_generate_tmp
		if [ ! -d "$app_path" ]; then
			cloud_generate_app
		else
			cloud_generate_dir
		fi
	else
		echo Already generated
	fi
}

cloud_init() {
	cloud_set_paths "$@"
	cloud_generate
	cloud_choose_settings
	cloud_set_remote
	complete
}

cloud_open() {
	cloud_load
	open "http://$vm_name:$rails_cluster_port"
}

cloud_bin() {
	cloud_set_paths
	path=$1
	name=$(basename $path)
	if cloud_dir_exists; then
		shift
		bin_path=bin/$name
		if [ -f $bin_path ]; then
			cmd=$bin_path
		else
			cmd=$name
		fi
		cloud_exec -- $cmd $@
	else
		alt=$(which -a $name | grep -A 1 $path | tail -n 1)
		if [ -z "$alt" ]; then
			error "No alternative found for \`$name\`"
		else
			$alt $@
		fi
	fi
}

cloud_delete_namespace() {
	begin Deleting Namespace
	vm_kubectl delete namespace $cloud_id
}

cloud_delete_dir() {
	begin Deleting Cloud Directory
	if [ ! -d "$cloud_path" ]; then
		rm -rf "$cloud_path"
	else
		echo Not found
	fi
}

cloud_destroy() {
	cloud_load
	cloud_delete_namespace
	cloud_delete_dir
	complete
}

cloud_apply() {
	begin Applying YAMLs
	vm_kubectl apply -k \"$cloud_apply_path\"
}

cloud_clear_builds() {
	begin Clearing Builds
	build_names=$(cloud_kubectl get pods --no-headers=true | awk '/-build/{ORS=" "; print $1}')
	if [ ! -z "$build_names" ]; then
		cloud_kubectl delete pods $build_names
	fi
}

cloud_build() {
	cloud_load
	cloud_clear_builds
	compile build
	cloud_apply
	complete
	echo "\nUse \`cloud log <pod-name>\` to see logs"
}

cloud_import_images() {
	begin Importing Images
	image_paths=$(find "$cloud_images_path" -name \*.tar)
	if [ ! -z $image_paths ]; then
		while read image_path; do
			name=$(basename $image_path | sed 's/\.tar//')
			default_tag=docker.io/library/image
			tag=docker.io/library/$name-$cloud_env
			sha=$(vm_ssh sudo k3s crictl images | grep $tag | awk '{ print $3 }')
			if [ ! -z $sha ]; then
				vm_ssh sudo k3s crictl rmi $sha
			fi
			vm_ssh sudo sh <<-SSH
				k3s ctr images import $image_path
				k3s ctr images tag $default_tag:latest $tag:latest
				k3s ctr images remove $default_tag:latest
			SSH
			rm $image_path
		done <<< $image_paths
	else
		echo Already imported
	fi
}

cloud_deploy() {
	cloud_load
	cloud_import_images
	compile deploy
	cloud_apply
	complete
}

cloud_undeploy() {
	cloud_load
	begin Undeploying
	cloud_kubectl delete --all deployments
	complete
}

cloud_restart() {
	cloud_load
	name=$(cloud_find_pod $1)
	cloud_kubectl delete pod $name
}

cloud_shell() {
	cloud_load
	name=$(cloud_find_pod $1)
	cloud_pod_exec $name /bin/bash
}

cloud_attach() {
	cloud_load
	name=$(cloud_find_pod $1)
	cloud_kubectl attach -it $name
}

cloud_tunnel() {
	cloud_load
	port=$(cloud_kubectl get service $1 --no-headers=true | awk '{ print $5 }' | sed 's/\/.*//')
	name=$(cloud_find_pod $1)
	cloud_kubectl port-forward $name $port:$port
}

cloud_exec() {
	cloud_load
	if [ $# -gt 2 ] && [ "$2" = -- ]; then
		name=$1
		shift 2
	elif [ $# -gt 1 ] && [ "$1" = -- ]; then
		shift
	else
		error Wrong format
	fi
	name=$(cloud_find_pod $name)
	cloud_pod_exec $name $@
}

cloud_status() {
	cloud_load
	if [ -z "$1" ]; then
		cloud_kubectl get pods
	else
		name=$(cloud_find_pod $1)
		cloud_kubectl describe pod $name
	fi
}

cloud_log() {
	cloud_load
	name=$(cloud_find_pod $1)
	cloud_kubectl logs -f $name
}

cloud_help() {
	unknown $1
	cat <<-DOC
		Usage: cloud <command> [options]
		Orchestrates Rails+Kubernetes Clouds.

		Available commands:
			install       Installs cloud
			uninstall     Uninstalls cloud
			update [tag]  Syncs latest or specific version
			init [path]   Generates directory and initializes
			destroy       Deletes directory and purges
			build         Builds docker images
			deploy        Deploys application
			undeploy      Undeploys application
			status [pod]  Prints status of pods (all by default)
			restart [pod] Restart pod (rails by default)
			shell [pod]   Opens bash shell in pod (rails by default)
			attach pod    Attachs into first process of pod (rails by default)
			tunnel pod    Creates temporary tunnel into pod
			exec [pod]    Executes shell command in pod (rails by default)
			open          Opens browser pointing to app
			log [pod]     Tails pod log (rails by default)
			envs          Manages environments
			vm            Manages virtual machine
			help          Prints documentation
	DOC
}

# ENVS

envs_list() {
	cloud_set_paths
	list=$(ls -1 "$cloud_envs_path")
	if [ -z "$list" ]; then
		error No environments found
	else
		echo "$list"
	fi
}

envs_add() {
	cloud_set_paths
	if ! cloud_env_exists $1; then
		begin Adding Environment $1
		mkdir -p "$cloud_envs_path"
		touch "$cloud_env_path"
		envs_edit_current
	else
		error Environment $1 already added
	fi
	complete
}

envs_edit_current() {
	edit "$cloud_env_path"
}

envs_edit() {
	cloud_set_paths
	cloud_ensure_env $1
	begin Editing Environment $1
	envs_edit_current
	complete
}

envs_delete() {
	cloud_set_paths
	cloud_ensure_env $1
	begin Deleting Environment $1
	rm -f "$cloud_env_path"
	complete
}

envs_help() {
	unknown $1
	cat <<-DOC
		Usage: cloud envs <command> [options]

		Available commands:
			list          Lists all
			add           Adds new
			edit          Edits existing
			delete        Delete existing 
			help          Prints documentation
	DOC
}

# VM

vm_net_exists() {
	if [ -f $user_conf_path ]; then
		for name in ${net_setting_names[@]}; do
			if cat $user_conf_path | grep $name >/dev/null 2>&1; then
				return 0
			fi
		done
		return 1
	else
		return 1
	fi
}

vm_running() {
	sudo launchctl list | grep $agent_name >/dev/null 2>&1
}

vm_ssh() {
	ssh -tq \
	-o 'ConnectTimeout=10' \
	-o 'ControlMaster=auto' \
	-o 'ControlPersist=600' \
	-o 'ControlPath=/tmp/%r@%h' \
	-o 'UserKnownHostsFile=/dev/null' \
	-o 'StrictHostKeyChecking=no' \
	$vm_user@$vm_name $@
}

vm_wait_ssh() {
	begin Waiting SSH
	while :; do
		vm_ssh exit
		printf .
		if [ $? -eq 0 ]; then
			echo
			break
		else
			sleep 30
		fi
	done
}

vm_kubectl() {
	cmd=$@
	if [ $context = remote ]; then
		case $cloud_provider in
		aws)
			cmd="--kubeconfig $aws_kubeconfig_path $cmd"
		;;
		esac
	fi
	vm_ssh sudo kubectl $cmd
}

vm_download() {
	begin Dowloading Images
	if [ ! -d $repo_vm_path ]; then
		mkdir $repo_vm_path
		curl -o $repo_initrd_path $s3_initrd_url
		curl -o $repo_vmlinuz_path $s3_vmlinuz_url
		curl -o $repo_disk_path $s3_disk_url
	else
		echo Already downloaded
	fi
}

vm_create_disk() {
	begin Creating Disk
	if [ ! -f $user_disk_path ]; then
		tar xJvf $repo_disk_path -C $user_cloud_path
	else
		echo Already created
	fi
}

vm_first_boot() {
	begin First Boot
	if ! vm_settings_exists; then
		while :; do
			echo Waiting to receive ip
			cloud vm start
			mkdir -p $tmp_path
			nc -l 1234 > $tmp_conf_path & sleep 30; kill $! >/dev/null 2>&1
			if [ -z "$(cat $tmp_conf_path)" ]; then
				vm_stop
			else
				break
			fi
		done
		. $tmp_conf_path
		cat $tmp_conf_path >> $user_conf_path
		rm $tmp_conf_path
	else
		echo Already booted
	fi
}

vm_add_host() {
	begin Adding Hostname
	if ! host_exists; then
		echo $vm_ip $vm_name | sudo tee -a $hosts_path
	else
		echo Already added
	fi
}

vm_share_home() {
	begin Sharing Home Directory
	if ! export_exists; then
		echo $exports_home_path -mapall=$(id -u) | sudo tee -a $exports_path
		sudo nfsd update
		vm_wait_ssh
		vm_ssh sudo sh <<-SSH
			echo "$mac_ip:$exports_home_path\t$HOME\tnfs local_lock=all\t0 0" >> /etc/fstab
			mkdir -p $HOME
			mount $HOME
		SSH
	else
		echo Already shared
	fi
}

vm_init() {
	begin Initializing Virtual Machine
	if [ -z $vm_id ]; then
		vm_id=$(gen_id)
		add_conf $user_conf_path vm_id
		vm_config nested
	else
		echo Already initialized
	fi
}

vm_install() {
	vm_download
	vm_init
	vm_create_disk
	vm_first_boot
	vm_add_host
	vm_share_home
	if [ "$1" != nested ]; then
		complete
	fi
}

vm_delete_agent() {
	begin Deleting Agent
	if [ -f $user_agent_path ]; then
		sudo rm $user_agent_path
	else
		echo Not found
	fi
}

vm_delete_net() {
	begin Deleting Network Settings
	if vm_settings_exists; then
		for name in ${net_setting_names[@]}; do
			sudo sed -i '' "/$name/d" $user_conf_path
		done
	else
		echo Not found
	fi
}

vm_delete_files() {
	begin Deleting Virtual Machine
	if [ -d $repo_vm_path ]; then
		rm -rf $repo_vm_path
		rm -rf $user_disk_path
	else
		echo Not found
	fi
}

vm_delete_hostname() {
	begin Deleting Hostname
	if host_exists; then
		sudo sed -i '' "/$vm_name/d" $hosts_path
	else
		echo Not found
	fi
}

vm_unshare_home() {
	begin Unsharing Home Directroy
	if export_exists; then
		escaped_exports_home_path=$(echo $exports_home_path | sed 's/\//\\\//g')
		sudo sed -i '' "/$escaped_exports_home_path/d" $exports_path
		sudo nfsd update
	else
		echo Not shared
	fi
}

vm_uninstall() {
	vm_stop
	vm_delete_agent
	if [ "$1" != nested ]; then
		vm_delete_net
		vm_delete_files
	fi
	vm_delete_hostname
	vm_unshare_home
	if [ "$1" != nested ]; then
		complete
	fi
}

vm_choose_settings() {
	begin Choosing Settings
	indexes=${!user_setting_names[@]}
	for i in $indexes; do
		desc=${user_setting_descs[$i]}
		value=${!user_setting_names[$i]}
		echo $desc: $value
	done
	if ! correct; then
		echo
		for i in $indexes; do
			desc=${user_setting_descs[$i]}
			name=${user_setting_names[$i]}
			value=${!user_setting_names[$i]}
			echo $desc: $value
			if ! correct; then
				echo "Enter new value: \c"
				read $name
			fi
			echo
		done
		touch $user_conf_path
		for i in $indexes; do
			name=${user_setting_names[$i]}
			value=${!user_setting_names[$i]}
			sudo sed -i '' "/$name/d" $user_conf_path
			echo $name=$value >> $user_conf_path
		done
		configure
	fi
}

vm_install_agent() {
	begin Installing Agent
	mkdir -p $(dirname $user_agent_path)
	cat <<-XML | sudo tee $user_agent_path >/dev/null
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
		<plist version="1.0">
			<dict>
				<key>Label</key>
				<string>com.cloud</string>
				<key>ProgramArguments</key>
				<array>
					<string>$repo_xhyve_path</string>
					<string>-A</string>
					<string>-U</string>
					<string>$vm_id</string>
					<string>-c</string>
					<string>$vm_cpus</string>
					<string>-m</string>
					<string>$vm_mem</string>
					<string>-s</string>
					<string>0,hostbridge</string>
					<string>-s</string>
					<string>2,virtio-net</string>
					<string>-s</string>
					<string>4,virtio-blk,$user_disk_path</string>
					<string>-f</string>
					<string>kexec,$repo_vmlinuz_path,$repo_initrd_path,root=/dev/vda1 ro</string>
				</array>
				<key>RunAtLoad</key>
				<true/>
			</dict>
		</plist>
	XML
}

vm_config() {
	vm_choose_settings
	vm_install_agent
	if [ "$1" != nested ]; then
		vm_restart
		complete
	fi
}

vm_start() {
	begin Starting Virtual Machine
	if ! vm_running; then
		sudo launchctl load -w $user_agent_path >/dev/null
		vm_wait_ssh		
	else
		echo Already running
	fi
	if [ "$1" != nested ]; then
		complete
	fi
}

vm_stop() {
	begin Stopping Virtual Machine
	if vm_running; then
		sudo launchctl unload -w $user_agent_path >/dev/null 2>&1
		while vm_running; do
			sleep 5
		done
	else
		echo Not running
	fi
	if [ "$1" != nested ]; then
		complete
	fi
}

vm_restart() {
	vm_stop nested
	vm_start nested
	complete
}

vm_exec() {
	if [ $# -gt 1 ] && [ "$1" = -- ]; then
		shift
	else
		error Wrong format
	fi
	vm_ssh $@
}

vm_update_packages() {
	begin Updating Packages
	vm_ssh sudo sh <<-SSH
		apt update
		DEBIAN_FRONTEND=noninteractive apt upgrade -y && apt autoremove -y
	SSH
}

vm_update_k3s() {
	begin Updating K3S
	regex='v[0-9]+\.[0-9]+\.[0-9]+\+k3s.?[0-9]+'
	current_version=$(vm_ssh k3s -v | grep -oE $regex)
	latest_version=$(curl -s $k3s_latest_url | grep -oE $regex | head -n1)
	if [ -z $current_version ] || [ $current_version != $latest_version ]; then
		url="https://github.com/rancher/k3s/releases/download/$latest_version/k3s"
		vm_ssh sudo sh <<-SSH
			systemctl stop k3s
			curl -Lo $k3s_path $url
			chmod +x $k3s_path
			systemctl start k3s
		SSH
	else
		echo Already updated
	fi
}

vm_update() {
	vm_update_packages
	vm_update_k3s
	complete
}

vm_help() {
	unknown $1
	cat <<-DOC
		Usage: cloud vm <command> [options]

		Available commands:
			install       Installs virtual machine
			uninstall     Uninstalls virtual machine
			start         Starts agent
			stop          Stops agent
			restart       Stops and starts agent
			shell         Opens bash shell
			exec          Executes command
			update        Updates operating system
			help          Prints documentation
	DOC
}

# AWS

aws() {
	vm_ssh aws $@
}

aws_create_repository() {
	if [ -z $rails_repo ]; then
		rails_repo=$(
			aws ecr create-repository \
			--repository-name $cloud_name |
			read_json repositoryUri
		)
		add_conf "$cloud_base_path" rails_repo
	else
		echo Already created
	fi
}

aws_delete_repository() {
	begin Delete Repository
	if [ ! -z $rails_repo ]; then
		aws ecr delete-repository --repository-name $cloud_name
		del_conf "$cloud_base_path" rails_repo
	else
		echo Not found
	fi
}

aws_create_role() {
	begin Creating Role
	if [ -z $aws_role_arn ]; then
		aws_role_policy=$(cat <<-JSON
			{
				"Version": "2012-10-17",
				"Statement": [
					{
						"Effect": "Allow",
						"Principal": {
							"Service": "eks.amazonaws.com"
						},
						"Action": "sts:AssumeRole"
					},
					{
						"Effect": "Allow",
						"Principal": {
							"Service": "ec2.amazonaws.com"
						},
						"Action": "sts:AssumeRole"
					}
				]
			}
		JSON
		)
		aws_role_arn=$(
			aws iam create-role \
			--role-name $cloud_name \
			--assume-role-policy-document \'$aws_role_policy\' |
			read_json Arn
		)
		add_conf "$cloud_remote_path" aws_role_arn
		for name in \
		AmazonEKSClusterPolicy \
		AmazonEKSServicePolicy \
		AmazonEKSWorkerNodePolicy \
		AmazonEKS_CNI_Policy \
		AmazonEC2ContainerRegistryReadOnly \
		AmazonRoute53FullAccess; do
			aws iam attach-role-policy \
			--role-name $cloud_name \
			--policy-arn arn:aws:iam::aws:policy/$name
		done
	else
		echo Already created
	fi
}

aws_delete_role() {
	begin Deleting Role
	if [ ! -z $aws_role_arn ]; then
		aws iam delete-role --role-name $cloud_name
		del_conf "$cloud_remote_path" aws_role_arn
	else
		echo Not found
	fi
}

aws_create_vpc() {
	begin Creating VPC
	if [ -z $aws_vpc_id ]; then
		aws_vpc_id=$(
			aws ec2 create-vpc --cidr-block 10.0.0.0/16 |
			read_json VpcId 
		)
		add_conf "$cloud_remote_path" aws_vpc_id
		for name in support hostnames; do
			aws ec2 modify-vpc-attribute \
			--enable-dns-$name \
			--vpc-id $aws_vpc_id
		done
		aws_route_table_id=$(
			aws ec2 describe-route-tables \
			--filters "Name=vpc-id,Values=$aws_vpc_id" |
			read_json RouteTableId
		)
		add_conf "$cloud_remote_path" aws_route_table_id
	else
		echo Already created
	fi
}

aws_delete_vpc() {
	begin Deleting VPC
	if [ ! -z $aws_vpc_id ]; then
		aws ec2 delete-vpc --vpc-id $aws_vpc_id
		del_conf "$cloud_remote_path" aws_vpc_id
	else
		echo Not found
	fi
}

aws_create_gateway() {
	aws_gateway_id=$(
		aws ec2 create-internet-gateway |
		read_json InternetGatewayId
	)
	add_conf "$cloud_remote_path" aws_gateway_id
	aws ec2 attach-internet-gateway \
	--vpc-id $aws_vpc_id \
	--internet-gateway-id $aws_gateway_id
	aws ec2 create-route \
	--route-table-id $aws_route_table_id \
	--gateway-id $aws_gateway_id \
	--destination-cidr-block 0.0.0.0/0
}

aws_delete_gateway() {
	begin Deleting Gateway
	if [ ! -z $aws_gateway_id ]; then
		aws ec2 delete-gateway --internet-gateway-id $aws_gateway_id
		del_conf "$cloud_remote_path" aws_gateway_id
	else
		echo Not found
	fi
}

aws_create_subnet() {
	begin Creating Subnet$1
	name=aws_subnet$1_id
	block=10.0.$1.0
	if []; then
		aws_subnet2_id=$(
			aws ec2 create-subnet \
			--vpc-id ${!name} \
			--cidr-block $block/24 \
			--availability-zone $2 |
			read_json SubnetId
		)
		add_conf "$cloud_remote_path" $name
	else
		echo Already created
	fi
}

aws_delete_subnet() {
	begin Deleting Subnet$1
	name=aws_subnet$1_id
	if [ -z ${!name} ]; then
		aws ec2 delete-subnet --subnet-id ${!name}
		del_conf "$cloud_remote_path" $name
	else
		echo Not found
	fi
}

aws_create_cluster() {
	begin Creating Cluster
	if [ -z $aws_cluster_name ]; then
		aws_cluster_name=$cloud_id
		aws eks create-cluster \
		--name $aws_cluster_name \
		--role-arn $aws_role_arn \
		--resources-vpc-config \
		subnetIds=$aws_subnet1_id,$aws_subnet2_id,endpointPrivateAccess=true,endpointPublicAccess=true \
		>/dev/null
		echo Waiting cluster to be active
		wait_for aws_cluster_status ACTIVE
		add_conf "$cloud_remote_path" aws_cluster_name
	else
		echo Already created
	fi
}

aws_cluster_status() {
	aws eks describe-cluster \
	--name $cloud_name |
	read_json status
}

aws_create_kubeconfig() {
	begin Creating Kubeconfig
	if [ -z $aws_kubeconfig_path ]; then
		aws_kubeconfig_path=/home/hacker/.kube/$cloud_name
		vm_ssh sudo sh <<-SSH
			mkdir -p ~/.kube
			rm -f $aws_kubeconfig_path
			aws eks update-kubeconfig \
			--name $cloud_name \
			--kubeconfig $aws_kubeconfig_path \
			>/dev/null
		SSH
		add_conf "$cloud_base_path" aws_kubeconfig_path
	else
		echo Already created
	fi
}

aws_create_nodegroup() {
	begin Creating Nodegroup
	if [ -z $aws_nodegroup_name ]; then
		aws_nodegroup_name=default
		aws eks create-nodegroup \
		--cluster-name $cloud_name \
		--node-role $aws_role_arn \
		--nodegroup-name $aws_nodegroup_name \
		--subnets $aws_subnet1_id $aws_subnet2_id \
		--scaling-config minSize=1,maxSize=1,desiredSize=1 \
		>/dev/null
		add_conf "$cloud_remote_path" aws_nodegroup_name
		echo Waiting nodegroup to be active
		wait_for aws_nodegroup_status ACTIVE
	else
		echo Already created
	fi
}

aws_nodegroup_status() {
	aws eks describe-nodegroup \
	--cluster-name $cloud_name \
	--nodegroup-name $aws_nodegroup_name |
	read_json status
}

aws_create_cloud() {
	aws_create_repository
	aws_create_role
	aws_create_vpc
	aws_create_gateway
	aws_create_subnet 1 us-east-2a
	aws_create_subnet 2 us-east-2b
	aws_create_cluster
	aws_create_kubeconfig
	aws_create_nodegroup
}

aws_delete_cloud() {
	aws_delete_nodegroup
	aws_delete_kubeconfig
	aws_delete_cluster
	aws_delete_route_table
	aws_delete_subnet 1
	aws_delete_subnet 2
	aws_delete_gateway
	aws_delete_vpc
	aws_delete_role
	aws_delete_repository
}

if [ -f $user_conf_path ]; then
	. $user_conf_path
fi

case $1 in
install)
	cloud_install
;;
uninstall)
	cloud_uninstall
;;
update)
	cloud_update
;;
init)
	shift
	cloud_init "$@"
;;
open)
	cloud_open
;;
destroy)
	cloud_destroy
;;
bin)
	shift 
	cloud_bin $@
;;
envs)
	case $2 in
	''|list)
		envs_list
	;;
	add)
		envs_add $3
	;;
	edit)
		envs_edit $3
	;;
	delete)
		envs_delete $3
	;;
	help)
		envs_help
	;;
	*)
		envs_help $1
	;;
	esac
;;
build)
	cloud_build
;;
deploy)
	cloud_deploy
;;
undeploy)
	cloud_undeploy
;;
restart)
	cloud_restart $2
;;
shell)
	cloud_shell $2
;;
attach)
	cloud_attach $2
;;
tunnel)
	cloud_tunnel $2
;;
exec)
	shift
	cloud_exec $@
;;
status)
	cloud_status $2
;;
log)
	cloud_log $2
;;
vm)
	case $2 in
	install)
		vm_install
	;;
	uninstall)
		vm_uninstall
	;;
	config)
		vm_config
	;;
	start)
		vm_start
	;;
	stop)
		vm_stop
	;;
	restart)
		vm_restart
	;;
	shell)
		vm_ssh
	;;
	exec)
		shift 2
		vm_exec $@
	;;
	update)
		vm_update
	;;
	help)
		vm_help
	;;
	*)
		vm_help $2
	;;
	esac
;;
help)
	cloud_help
;;
*)
	cloud_help $1
;;
esac
